{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FogH0Q_3kNBu"
   },
   "source": [
    "# AI CopyWriter\n",
    "\n",
    "Прототип перефразирования и/или распространения текста на основе ruGPT3Large.\n",
    "\n",
    "Ссылка на COLAB https://colab.research.google.com/github/dilyararimovna/text_expansion/blob/main/Text_Expansion.ipynb\n",
    "\n",
    "### Установим необходимые зависимости:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "COu3KZ_Ee6OC"
   },
   "outputs": [],
   "source": [
    "!pip3 install urllib3==1.25.4\n",
    "\n",
    "!pip3 install transformers==2.8.0\n",
    "\n",
    "!pip install pymorphy2==0.8\n",
    "\n",
    "!pip install spacy==2.1.9\n",
    "\n",
    "!python3 -m spacy download xx_ent_wiki_sm\n",
    "\n",
    "!pip install deeppavlov\n",
    "\n",
    "!pip3 uninstall tensorflow --yes\n",
    "\n",
    "!pip3 install tensorflow-gpu==1.15.2\n",
    "\n",
    "!python3 -m  deeppavlov install syntax_ru_syntagrus_bert\n",
    "\n",
    "! pip3 install jsonlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tu7vpJHtSA-y"
   },
   "source": [
    "### Now several cells with the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pEBehO7le34Q"
   },
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import string  \n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymorphy2\n",
    "import spacy\n",
    "import xx_ent_wiki_sm\n",
    "from deeppavlov import build_model, configs\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "nlp = xx_ent_wiki_sm.load()\n",
    "nlp.add_pipe(nlp.create_pipe('sentencizer'), first=True)\n",
    "\n",
    "syntax_model = build_model(configs.syntax.syntax_ru_syntagrus_bert, download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W72yRHXDe34Q"
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel,GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"sberbank-ai/rugpt3large_based_on_gpt2\")\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(\"sberbank-ai/rugpt3large_based_on_gpt2\")\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "model.to(device)\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "3dQJTlD8e34Q"
   },
   "outputs": [],
   "source": [
    "russian_restricted_pronouns = \"я мной меня мною мне мы нас нам нами ты тебя тебе тобою тобой вы вас вам вами\".split()\n",
    "extra_marks = re.compile(r\"&[a-zA-Z0-9;]+\")\n",
    "expanding_startings = [\n",
    "    \"В то же время\", \n",
    "    \"Это так\", \n",
    "    \"Действительно,\", \n",
    "    \"Потому что\", \n",
    "    \"А главное,\", \n",
    "    \"При этом\",\n",
    "    \"В связи с этим\",\n",
    "    \"Кроме того,\",\n",
    "    \"Интересно, что\",\n",
    "    \"Также\",\n",
    "    ]\n",
    "\n",
    "\n",
    "def join_words_in_or_pattern(words):\n",
    "    return \"(\" + \"|\".join([r'\\b%s\\b' % word for word in words]) + \")\"\n",
    "\n",
    "\n",
    "RU_PRONOUNS = re.compile(join_words_in_or_pattern(russian_restricted_pronouns), re.IGNORECASE)\n",
    "\n",
    "\n",
    "def generate_rugpt3large(prompt_text, return_only_predicted=False,\n",
    "                         till_new_string=True, generate_only_one_sent=True, \n",
    "                         length=100, temperature=1.0, k=10, p=0.9, repetition_penalty=1.0,\n",
    "                         num_return_sequences=1, stop_token=\"</s>\"):\n",
    "    global device\n",
    "    total_sequence = \"\"\n",
    "    if num_return_sequences > 1:\n",
    "        all_sequences = []\n",
    "    \n",
    "    encoded_prompt = tokenizer.encode(\n",
    "        prompt_text, add_special_tokens=False, return_tensors=\"pt\")\n",
    "    encoded_prompt = encoded_prompt.to(device)\n",
    "\n",
    "    output_sequences = model.generate(\n",
    "                input_ids=encoded_prompt,\n",
    "                max_length=length + len(encoded_prompt[0]),\n",
    "                temperature=temperature,\n",
    "                top_k=k,\n",
    "                top_p=p,\n",
    "                repetition_penalty=repetition_penalty,\n",
    "                do_sample=True,\n",
    "                num_return_sequences=num_return_sequences,\n",
    "            )\n",
    "    \n",
    "    if len(output_sequences.shape) > 2:\n",
    "        output_sequences.squeeze_()\n",
    "\n",
    "    for generated_sequence_idx, generated_sequence in enumerate(output_sequences):\n",
    "        generated_sequence = generated_sequence.tolist()\n",
    "        \n",
    "        text = tokenizer.decode(generated_sequence, clean_up_tokenization_spaces=True)\n",
    "        text = text[: text.find(stop_token) if stop_token else None]\n",
    "\n",
    "        total_sequence = (text[len(tokenizer.decode(\n",
    "            encoded_prompt[0], clean_up_tokenization_spaces=True)) :])\n",
    "        total_sequence = re.sub(r\"[\\\"'«»]\", \"\", total_sequence)\n",
    "        total_sequence = total_sequence.strip()\n",
    "        \n",
    "        if till_new_string:\n",
    "            total_sequence = total_sequence[:total_sequence.find(\"\\n\")].strip()\n",
    "            \n",
    "        if generate_only_one_sent:\n",
    "            total_sequence = \" \".join([sent.text for sent in nlp(total_sequence).sents][:1])\n",
    "            \n",
    "        if len(total_sequence) > 1 and prompt_text[-1] in [\".\", \"!\", \"?\", \"…\"]:\n",
    "            total_sequence = total_sequence[0].upper() + total_sequence[1:]\n",
    "            \n",
    "        if not return_only_predicted:\n",
    "            if len(total_sequence) > 1 and total_sequence[0] in [\".\", \"!\", \"?\", \"…\", \",\"]:\n",
    "                total_sequence = prompt_text + total_sequence\n",
    "            else:\n",
    "                total_sequence = prompt_text + \" \" + total_sequence\n",
    "        else:\n",
    "            if len(total_sequence) > 1 and total_sequence[0] in [\".\", \"!\", \"?\", \"…\", \",\"]:\n",
    "                total_sequence = total_sequence\n",
    "            else:\n",
    "                total_sequence = \" \" + total_sequence\n",
    "        \n",
    "        if num_return_sequences > 1 and len(total_sequence) > 0:\n",
    "            all_sequences.append(total_sequence)\n",
    "            \n",
    "    if num_return_sequences > 1:\n",
    "        return all_sequences\n",
    "    else:\n",
    "        return total_sequence\n",
    "    \n",
    "\n",
    "def get_nsubjects(text):\n",
    "    nsubjects = []\n",
    "    for parse in syntax_model([text]):\n",
    "        for row in parse.split(\"\\n\"):\n",
    "            if \"nsubj\" in row:\n",
    "                nsubjects.append(row.split(\"\\t\")[1])\n",
    "\n",
    "    return nsubjects\n",
    "\n",
    "\n",
    "def is_satisfying(sent):\n",
    "    doc = nlp(sent)\n",
    "    if len(doc.ents) > 0:\n",
    "        return False\n",
    "    \n",
    "    ntokens = len(sent.split())\n",
    "    if 15 <= ntokens or ntokens < 5:\n",
    "        return False\n",
    "    if re.search(RU_PRONOUNS, sent):\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "def generate_paraphrase(text):\n",
    "    predictions = generate_rugpt3large(f\"{text} Перефразирую:\", \n",
    "                                       return_only_predicted=True, \n",
    "                                       num_return_sequences=10)\n",
    "    predictions = [p.strip() for p in predictions]\n",
    "    predictions = [p for p in predictions if len(p) > 1]\n",
    "    original_tokens = set(text.split())\n",
    "    nsubjects = set(get_nsubjects(text))\n",
    "    \n",
    "    total_n_tokens = []\n",
    "    total_same_tokens = []\n",
    "    total_same_nsubjects = []\n",
    "    \n",
    "    for pred_par in predictions:\n",
    "        pred_tokens = pred_par.split()\n",
    "        \n",
    "        len_pred_tokens = len(pred_tokens)\n",
    "        len_same_tokens = len(original_tokens.intersection(set(pred_tokens)))\n",
    "        len_same_nsubjs = len(nsubjects.intersection(set(pred_tokens)))\n",
    "        \n",
    "        total_n_tokens.append(len_pred_tokens)\n",
    "        total_same_tokens.append(len_same_tokens)\n",
    "        total_same_nsubjects.append(len_same_nsubjs)\n",
    "    \n",
    "    targets = [st * sn / tt for st, sn, tt in \n",
    "               zip(total_same_tokens, total_same_nsubjects, total_n_tokens)]\n",
    "    # if all([el <= 1 for el in total_same_nsubjects]):\n",
    "    if sum(total_same_nsubjects) == 0:\n",
    "        targets = [st / tt for st, sn, tt in \n",
    "                   zip(total_same_tokens, total_same_nsubjects, total_n_tokens)]\n",
    "    targets = [t if predictions[i] != text else 0 for i, t in enumerate(targets)]\n",
    "    best_pred_id = np.argmax(targets)\n",
    "    \n",
    "    new_sent_text = predictions[best_pred_id]\n",
    "    if len(new_sent_text) > 1:\n",
    "        if new_sent_text[-1] not in [\".\", \"!\", \"?\", \"…\"]:\n",
    "            new_sent_text = new_sent_text + \".\"\n",
    "        new_sent_text = new_sent_text[0].upper() + new_sent_text[1:]\n",
    "    else:\n",
    "        new_sent_text = text\n",
    "    return new_sent_text\n",
    "\n",
    "    \n",
    "def expand_text(text, paraphrase=False, max_history_sents=5):\n",
    "    expanded = deepcopy(text)\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    expanded_sents = []\n",
    "    sents_texts = [sent.text for sent in doc.sents if len(sent.text) > 1]\n",
    "    for sent_id, sent in enumerate(doc.sents):\n",
    "        if len(sent.text) <= 1:\n",
    "            continue\n",
    "        expanded_sents.append(sent.text)\n",
    "        \n",
    "        expand_sent = \"\"\n",
    "        if sent_id < len(sents_texts) - 1 and {\"CONJ\"} in morph.parse(sents_texts[sent_id + 1].split()[0])[0].tag:\n",
    "            pass\n",
    "        else:\n",
    "            expanding_start = random.choice(expanding_startings)\n",
    "            context = \" \".join(expanded_sents[-max_history_sents:])\n",
    "            generated = generate_rugpt3large(f\"{context} {expanding_start}\",\n",
    "                                             return_only_predicted=True, num_return_sequences=5)\n",
    "            \n",
    "            for gen in generated:\n",
    "                if is_satisfying(gen):\n",
    "                    expand_sent = f\"{expanding_start}{gen}\".strip()\n",
    "                    if expand_sent[-1] not in [\".\", \"!\", \"?\", \"…\"]:\n",
    "                        expand_sent = expand_sent + \".\"\n",
    "                    break\n",
    "        \n",
    "        new_subtext = deepcopy(sent.text)\n",
    "        if paraphrase:\n",
    "            new_sent_text = generate_paraphrase(sent.text).strip()\n",
    "            if len(new_sent_text) > 1:\n",
    "                if new_sent_text[-1] not in [\".\", \"!\", \"?\", \"…\"]:\n",
    "                    new_sent_text = new_sent_text + \".\"\n",
    "                new_sent_text = new_sent_text[0].upper() + new_sent_text[1:]\n",
    "            else:\n",
    "                new_sent_text = deepcopy(sent.text)\n",
    "                \n",
    "            if len(expand_sent) > 0:\n",
    "                new_subtext = f\"{new_sent_text} {expand_sent}\"\n",
    "                expanded_sents.append(f\"{expand_sent}\")\n",
    "            else:\n",
    "                new_subtext = f\"{new_sent_text}\"\n",
    "        else:\n",
    "            if len(expand_sent) > 0:\n",
    "                new_subtext = f\"{sent.text} {expand_sent}\"\n",
    "                expanded_sents.append(f\"{expand_sent}\")\n",
    "                \n",
    "        expanded = expanded.replace(sent.text, new_subtext)\n",
    "        \n",
    "                \n",
    "    expanded = expanded.strip()\n",
    "    if abs(len(expanded) - len(text)) < 10:\n",
    "        expanded = expand_text(text, max_history_sents=5)\n",
    "    return expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "eokhjyFpe34Q"
   },
   "outputs": [],
   "source": [
    "def paraphrase_and_expand_text(text, paraphrase=False, expand=False, \n",
    "                               max_history_sents=5):\n",
    "    text = text.strip()\n",
    "    if expand:\n",
    "        paraphrased_expanded = expand_text(text, \n",
    "                                           paraphrase=paraphrase, \n",
    "                                           max_history_sents=max_history_sents)\n",
    "    elif paraphrase:\n",
    "        paraphrased_expanded = \"\"\n",
    "        doc = nlp(text)\n",
    "        for sent_id, sent in enumerate(doc.sents):\n",
    "            if len(sent.text) <= 1:\n",
    "                continue\n",
    "\n",
    "            if paraphrase:\n",
    "                par_sent = generate_paraphrase(sent.text)\n",
    "                paraphrased_expanded += f\" {par_sent}\"\n",
    "    paraphrased_expanded = re.sub(extra_marks, \"\", paraphrased_expanded)\n",
    "    return paraphrased_expanded.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mezkuo78Nc9h"
   },
   "source": [
    "# DEMO Usage\n",
    "\n",
    "Итак, все зависимости установлены, функции определены. Самое время просто воспользоваться DEMO. \n",
    "Пользователь демонстрации может изменять список текстов, и главное параметры `paraphrase` и `expand`. Параметр `paraphrase` отвечает за то, будет ли исходный текст перефразирован, а параметр `expand` показывает следует ли модели дополнить текст. Эти режимы могут быть включены как по отдельности, так и вместе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g-4xfmhee34Q",
    "outputId": "f7bba57a-786e-4b88-bf90-1ce0c2f2b805"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: На мой взгляд, лето – прекраснейшее время года, поскольку очень тепло, вокруг все красиво, и у нас имеется отличная возможность отдохнуть. \n",
      "             А еще лето – это время каникул и отпусков. \n",
      "             Мы можем отправиться куда угодно, замечательно провести время у водоема, в тени изумрудной зелени, плескаться в теплой воде. \n",
      "             А можно отправиться в горы, носиться на велосипеде или играть во всевозможные игры.\n",
      "\n",
      "Rewritten Text: Лето – прекрасная пора, когда все красиво, все вокруг прекрасно и у нас есть замечательная возможность отдохнуть! Лето – это время каникул и отпусков. Также в это время можно заниматься любимым делом. Мы можем отправиться в любое место и провести там время. А можно и не ехать в горы, а заняться чем-нибудь полезным и интересным! Это так прекрасно, когда можно отдохнуть от городской суеты.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: Лето – это всегда особенное время года и каждый человек старается сделать его запоминающимся. \n",
      "             Тут пригодится умение замечать простые мелочи, впитывать в себя солнечные и радостные моменты каждого дня. \n",
      "             Даже если на улице идет дождь, поездка на море отменяется, а любимое мороженное в магазине закончилось. \n",
      "             Ведь это всего лишь отдельные дни и в целом лето это калейдоскоп ярких переживаний, который мы держим в своих руках.\n",
      "\n",
      "Rewritten Text: Лето – это лучшее время года для отдыха на природе! А главное, чтобы этот праздник запомнился на долго! Я – человек, и все в мире – люди, и я – человек. Кроме того, нужно научиться радоваться тому, что имеешь, и ценить то, что есть. Если на улице идет дождь, поездка на море отменяется. Всего лишь отдельные дни и в целом лето это калейдоскоп ярких переживаний, который мы держим в своих руках.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: Тысячи капель прохладной воды падают на лицо и стекают по волосам и телу, солнце нежно щекотит кожу, а ты вдыхаешь запах сочной листвы. \n",
      "             И вы не просто мажете тело обёртыванием или наносите на лицо сыворотку, вы совершаете ритуал любви к себе, своей коже и своему телу. \n",
      "             Это волшебное время, когда девушка находиться наедине с собой. Она вся в своих мыслях, она приводит не только себя в порядок, но и свой разум. \n",
      "             Восстанавливается после тяжелого дня или наоборот, только готовится к нему, чтобы быть бодрой и энергичной.\n",
      "\n",
      "Rewritten Text: Ты вдыхаешь запах сочной листвы и смотришь на облака. Вы не просто мажете тело обёртыванием или наносите на лицо сыворотку, вы совершаете ритуал любви к себе, своей коже и своему телу. Когда девушка не знает, что она хочет, она может только хотеть. Также это время, когда она может расслабиться, отдохнуть и набраться сил для следующего дня. Она не хочет, она не может, она не хочет. В то же время, она может побыть одна, наедине с собой, а может и с другим мужчиной. Как только вы проснулись, вы уже готовы к трудным делам. Это так же время, когда можно начать новую жизнь.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text in [\n",
    "             \"\"\"На мой взгляд, лето – прекраснейшее время года, поскольку очень тепло, вокруг все красиво, и у нас имеется отличная возможность отдохнуть. \n",
    "             А еще лето – это время каникул и отпусков. \n",
    "             Мы можем отправиться куда угодно, замечательно провести время у водоема, в тени изумрудной зелени, плескаться в теплой воде. \n",
    "             А можно отправиться в горы, носиться на велосипеде или играть во всевозможные игры.\"\"\",\n",
    "             \"\"\"Лето – это всегда особенное время года и каждый человек старается сделать его запоминающимся. \n",
    "             Тут пригодится умение замечать простые мелочи, впитывать в себя солнечные и радостные моменты каждого дня. \n",
    "             Даже если на улице идет дождь, поездка на море отменяется, а любимое мороженное в магазине закончилось. \n",
    "             Ведь это всего лишь отдельные дни и в целом лето это калейдоскоп ярких переживаний, который мы держим в своих руках.\"\"\",\n",
    "             \"\"\"Тысячи капель прохладной воды падают на лицо и стекают по волосам и телу, солнце нежно щекотит кожу, а ты вдыхаешь запах сочной листвы. \n",
    "             И вы не просто мажете тело обёртыванием или наносите на лицо сыворотку, вы совершаете ритуал любви к себе, своей коже и своему телу. \n",
    "             Это волшебное время, когда девушка находиться наедине с собой. Она вся в своих мыслях, она приводит не только себя в порядок, но и свой разум. \n",
    "             Восстанавливается после тяжелого дня или наоборот, только готовится к нему, чтобы быть бодрой и энергичной.\"\"\"]:\n",
    "\n",
    "    rewritten_text = paraphrase_and_expand_text(text, paraphrase=True, expand=True)\n",
    "    print(f\"Original Text: {text}\\n\\nRewritten Text: {rewritten_text}\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kPZKhTgxe34R"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Text_Expansion.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Torch_Bert",
   "language": "python",
   "name": "torch_bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
